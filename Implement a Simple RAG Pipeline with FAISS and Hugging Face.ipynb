{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6df39f7-2f0e-45a0-9484-768e3cf31220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79c23bcc-0258-41d2-bd81-d1848576912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Deep learning models are solving complex problems.\",\n",
    "    \"Generative AI can create lifelike images and videos.\",\n",
    "    \"AI models need optimization to reduce biases.\",\n",
    "    \"Natural language processing enables better human-computer interaction.\",\n",
    "    \"Computer vision algorithms can detect objects in real-time.\",\n",
    "    \"Reinforcement learning helps agents learn optimal strategies.\",\n",
    "    \"Transfer learning accelerates model training on new tasks.\",\n",
    "    \"Attention mechanisms have revolutionized sequence modeling.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8a16c8-b47c-4389-98e3-15fcde109c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (8, 384)\n",
      "Number of vectors in index: 8\n"
     ]
    }
   ],
   "source": [
    "# Create Embeddings and Index\n",
    "\n",
    "# 1. Load embedding model\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")   # 384‑dim embeddings\n",
    "\n",
    "# 2. Generate embeddings\n",
    "\n",
    "embeddings = model.encode(documents, convert_to_numpy=True)\n",
    "\n",
    "print(\"Embedding shape:\", embeddings.shape)   # should be (num_docs, 384)\n",
    "\n",
    "# 3. Create FAISS index\n",
    "\n",
    "embedding_dim = embeddings.shape[1]           # must match model output\n",
    "index = faiss.IndexFlatL2(embedding_dim)      # simple L2 similarity index\n",
    "\n",
    "# 4. Add embeddings to index\n",
    "\n",
    "index.add(embeddings)\n",
    "\n",
    "# 5. Verify index size\n",
    "\n",
    "print(\"Number of vectors in index:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6da7bf7-65d8-4c27-9234-134e4a1fb74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Documents:\n",
      "- Attention mechanisms have revolutionized sequence modeling.\n",
      "- AI models need optimization to reduce biases.\n",
      "- Reinforcement learning helps agents learn optimal strategies.\n",
      "\n",
      "--- Baseline Response ---\n",
      "Attention mechanisms help models focus on important parts of the input sequence.\n",
      "\n",
      "--- RAG-Enhanced Response ---\n",
      "Attention mechanisms help models focus on important parts of the input sequence.\n"
     ]
    }
   ],
   "source": [
    "# Task 3\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1. Define a simple query\n",
    "\n",
    "query = \"How do attention mechanisms improve AI models?\"\n",
    "\n",
    "# Embed the query\n",
    "query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "\n",
    "# 2. Retrieve top-k documents\n",
    "\n",
    "k = 3\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "retrieved_docs = [documents[i] for i in indices[0]]\n",
    "\n",
    "print(\"Retrieved Documents:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(\"-\", doc)\n",
    "\n",
    "# 3. Create enhanced prompt\n",
    "\n",
    "context_block = \"\\n\".join(f\"- {doc}\" for doc in retrieved_docs)\n",
    "\n",
    "enhanced_prompt = f\"\"\"\n",
    "You are an AI assistant. Use the context below to answer the question.\n",
    "\n",
    "Context:\n",
    "{context_block}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# 4. Baseline response (no retrieval)\n",
    "\n",
    "def mock_llm(prompt):\n",
    "    # Replace this with your real LLM call later\n",
    "    return \"Attention mechanisms help models focus on important parts of the input sequence.\"\n",
    "\n",
    "baseline_response = mock_llm(query)\n",
    "\n",
    "# 5. Enhanced RAG response\n",
    "# -----------------------------\n",
    "rag_response = mock_llm(enhanced_prompt)\n",
    "\n",
    "# 6. Compare responses\n",
    "# -----------------------------\n",
    "print(\"\\n--- Baseline Response ---\")\n",
    "print(baseline_response)\n",
    "\n",
    "print(\"\\n--- RAG-Enhanced Response ---\")\n",
    "print(rag_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aab70122-c6ed-44e6-af88-3b69f2bc59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_llm(prompt):\n",
    "    \"\"\"\n",
    "    A simple simulated LLM that uses retrieved context.\n",
    "    It looks for the 'Context:' block and incorporates it into the answer.\n",
    "    \"\"\"\n",
    "    if \"Context:\" in prompt:\n",
    "        context = prompt.split(\"Context:\")[1].split(\"Question:\")[0].strip()\n",
    "        return f\"Based on the retrieved context, here is the answer:\\n\\n{context}\\n\\nIn summary, attention mechanisms improve sequence modeling by allowing models to focus on the most relevant parts of the input.\"\n",
    "    else:\n",
    "        return \"Attention mechanisms help models focus on important parts of the input sequence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b51cf2e2-dfe8-4b6a-8ed4-bf270721a236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Baseline Response ---\n",
      "Attention mechanisms help models focus on important parts of the input sequence.\n",
      "\n",
      "--- RAG-Enhanced Response ---\n",
      "Based on the retrieved context, here is the answer:\n",
      "\n",
      "- Attention mechanisms have revolutionized sequence modeling.\n",
      "- AI models need optimization to reduce biases.\n",
      "- Reinforcement learning helps agents learn optimal strategies.\n",
      "\n",
      "In summary, attention mechanisms improve sequence modeling by allowing models to focus on the most relevant parts of the input.\n"
     ]
    }
   ],
   "source": [
    "baseline_response = mock_llm(query)\n",
    "\n",
    "# 5. Enhanced RAG response\n",
    "# -----------------------------\n",
    "rag_response = mock_llm(enhanced_prompt)\n",
    "\n",
    "# 6. Compare responses\n",
    "# -----------------------------\n",
    "print(\"\\n--- Baseline Response ---\")\n",
    "print(baseline_response)\n",
    "\n",
    "print(\"\\n--- RAG-Enhanced Response ---\")\n",
    "print(rag_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7813d264-c453-4d18-b122-90d6f3a0c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.57.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.12.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from accelerate) (2.9.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.0.0->accelerate) (3.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kanan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 7.3 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Kanan\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91229424-93dd-41ff-9109-4958847827e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "619d3d90-53e1-4aea-af1d-eba08c6a38c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817b8874b7af4646897ebea8612c1b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kanan\\.cache\\huggingface\\hub\\models--TinyLlama--TinyLlama-1.1B-Chat-v1.0. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8778c4fc94242ea88f1fdcae7e58c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3e6f32a5924f5e9676d06a6a4aea41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921cba38f6d64b41a02d6baf0ff7b838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0eee86a3d134652919744d3eb82733a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5db0d5e2df4623a0344c87e6f0c3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f2e4ada1d64efbb1e6ad91673a536a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # public, no token needed\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8babd41-25a5-4ed0-9a06-b01ff80a6982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model in RAG_pipeline \n",
    "\n",
    "def llama_generate(prompt, max_tokens=200):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(llama_model.device)\n",
    "    outputs = llama_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        temperature=0.2,\n",
    "        do_sample=True\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f6e39c5-43c6-448f-9b9b-332404dfac55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Baseline Response ---\n",
      "Attention mechanisms help models focus on important parts of the input sequence.\n",
      "\n",
      "--- RAG-Enhanced Response ---\n",
      "\n",
      "You are an AI assistant. Use the context below to answer the question.\n",
      "\n",
      "Context:\n",
      "- Attention mechanisms have revolutionized sequence modeling.\n",
      "- AI models need optimization to reduce biases.\n",
      "- Reinforcement learning helps agents learn optimal strategies.\n",
      "\n",
      "Question:\n",
      "How do attention mechanisms improve AI models?\n",
      "\n",
      "Answer:\n",
      "Attention mechanisms help AI models focus on specific parts of the input sequence. This helps reduce the impact of noise and distracting information. By focusing on the most important parts of the sequence, AI models can learn optimal strategies for solving problems.\n"
     ]
    }
   ],
   "source": [
    "# Compare Baseline vs RAG‑Enhanced Responses\n",
    "\n",
    "baseline_response = mock_llm(query)\n",
    "\n",
    "# 5. Enhanced RAG response\n",
    "# -----------------------------\n",
    "rag_response = llama_generate(enhanced_prompt)\n",
    "\n",
    "# 6. Compare responses\n",
    "# -----------------------------\n",
    "print(\"\\n--- Baseline Response ---\")\n",
    "print(baseline_response)\n",
    "\n",
    "print(\"\\n--- RAG-Enhanced Response ---\")\n",
    "print(rag_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c0d7b2-badb-40c1-b5b8-983b537b687b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
